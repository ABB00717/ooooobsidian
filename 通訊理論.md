通訊的數學理論的本質，在於將資訊傳輸的工程挑戰與隨機過程的統計結構結合，從而對資訊本身進行精確的數學量化，並確定資訊能夠在給定條件下可靠傳輸的最高速率。

這門學科的誕生，是為了解決如何在某一點準確或近似地重現另一個點所選定的訊息這一根本工程問題。為了有效解決此問題，理論衍生出了三大核心概念或支柱：

1. **資訊的量化（熵 $H$）：** 使用對數測度來量化從一組可能訊息中做出選擇時所產生的資訊量或不確定性，並將其推廣至涵蓋訊息的統計結構。
2. **頻道的限制（容量 $C$）：** 定義頻道能夠傳輸資訊的最大速率，這是系統的固有屬性，尤其考慮到雜訊的影響。
3. **編碼與冗餘度：** 通過將訊息源描述為隨機過程（例如馬可夫過程），分析其內在的統計結構和冗餘度，並利用編碼操作將資訊源與頻道進行「統計匹配」，以達到最大的傳輸效率和抗雜訊能力。

這些概念彼此關聯，共同解決核心問題。**無雜訊頻道**的基礎定理指出，如果資訊源的熵為 $H$，頻道容量為 $C$，則最大傳輸速率為 $C/H$ 符號每秒，這證明了熵是傳輸所需的頻道容量的決定因素。對於**有雜訊頻道**，雖然無法保證完全零錯誤，但基礎定理指出，我們可以利用編碼以速率 $C$ 傳輸資訊，且錯誤頻率可任意小，從而確立了 $C$ 作為該頻道的絕對速率上限。

---

## 內容講解

### **引言 (INTRODUCTION)**

本論文旨在擴展通訊理論，特別關注頻道的**雜訊效應**，以及如何利用原始訊息的**統計結構**和資訊最終目的地的性質來節省資源。通訊的根本問題，是確保在某一點準確或近似地重現另一個點所選定的訊息。儘管訊息通常具有語義（意指與物理或概念實體相關聯），但這些語義層面對工程問題而言是無關緊要的。關鍵在於實際訊息是從一組可能的訊息中選擇出來的。

### **資訊的衡量：對數測度 (Logarithmic Measure of Information)**

當訊息集中的所有選擇具有相同的機率時，資訊的衡量被視為可能訊息數量的對數函數。對數測度是最適當的選擇，原因包括：它在實際工程上更為有用，例如時間、頻寬等參數傾向於與可能性數量的對數呈線性變化；它更接近我們對適當測度的直覺感受；以及它在數學上更為合適，能簡化許多極限運算。

資訊的單位取決於對數的底數：

- 若底數為 2，單位稱為**二進制數位 (binary digits)，簡稱位元 (bits)**。一個具有兩個穩定狀態的設備，例如繼電器或觸發電路，可以儲存一位元資訊。
- 若底數為 10，單位稱為**十進制數位 (decimal digits)**。一個十進制數位約等於 3.32 位元。
- 若使用底數 $e$，則單位稱為**自然單位 (natural units)**。

### **通訊系統的架構 (Schematic diagram of a general communication system)**

通訊系統本質上由五個部分組成：

1. **資訊源 (Information source):** 產生要傳達給接收終端的訊息或訊息序列。訊息的類型多樣，例如電報中的字母序列、無線電中的時間函數 $f(t)$，或彩色電視中的多個三維函數 $f(x, y, t)$。
2. **發射器 (Transmitter):** 對訊息進行操作，產生適合在頻道上傳輸的訊號。操作可能包括簡單的轉換（如聲音壓力轉為電流），或複雜的編碼、採樣、量化和交錯（如多工 PCM 系統）。
3. **頻道 (Channel):** 用於傳輸訊號的介質，如電線、同軸電纜、無線電頻帶或光束。
4. **接收器 (Receiver):** 通常執行與發射器相反的操作，從訊號中重建訊息。
5. **目的地 (Destination):** 訊息的預定接收者或物體。

通訊系統大致可分為**離散 (discrete)**（訊息和訊號均為離散符號序列，如電報）、**連續 (continuous)**（訊息和訊號均視為連續函數，如無線電）和**混合 (mixed)** 三大類。

### **離散無雜訊系統 (PART I: DISCRETE NOISELESS SYSTEMS)**

#### **1. 離散無雜訊頻道 (THE DISCRETE NOISELESS CHANNEL)**

離散頻道是一種傳輸系統，允許從一組有限的基本符號 $S_1; \dots; S_n$ 中選擇序列。

- **頻道容量的定義 (Definition of Channel Capacity $C$):** 離散頻道的容量 $C$ 定義為 $C = \text{Lim}_{T\to\infty} \frac{\log N(T)}{T}$，其中 $N(T)$ 是持續時間 $T$ 允許的訊號數量。
- 在符號長度不同且序列受到限制的更一般情況下，例如電報中的點、劃和間隔的約束，頻道容量 $C$ 等於 $W$ 的對數 $\log W$，其中 $W$ 是由決定式方程 $\left|\sum_s W^{-b^{(s)}_{ij}} - \delta_{ij}\right| = 0$ 的最大實根。

#### **2. 離散資訊源 (THE DISCRETE SOURCE OF INFORMATION)**

資訊源的數學描述方式是將其視為**隨機過程 (stochastic process)**，該過程根據一組概率產生符號序列。

- **馬可夫過程 (Markoff Process):** 來源的複雜統計結構可以通過定義一組轉移概率 $p_i(j)$ 來描述，即前一個字母 $i$ 之後出現字母 $j$ 的概率。
- **近似語言結構 (Approximating Language Structure):** 可以使用人工語言來近似自然語言的統計特性。例如，對英文的近似包括：
    - **零階近似 (Zero-order approximation):** 符號獨立且等概率。
    - **一階近似 (First-order approximation):** 符號獨立，但使用英文文本中的實際字母頻率。
    - **二階近似 (Second-order approximation):** 引入雙字母結構（考慮 $p_i(j)$）。
    - **三階近似 (Third-order approximation):** 引入三字母結構（考慮前兩個字母的影響）。

#### **5. 遍歷源和混合源 (ERGODIC AND MIXED SOURCES)**

在通訊理論中，**遍歷源 (ergodic sources)** 具有特殊的意義。

- **遍歷性質 (Ergodic property):** 意味著統計上的均勻性。由該過程產生的每個序列在統計特性上都是相同的。對於遍歷過程，沿著單個序列的平均值（例如字母頻率）與所有可能序列的集合平均值（概率）是相等的（除了概率為零的集合）。

#### **6. 選擇、不確定性和熵 (CHOICE, UNCERTAINTY AND ENTROPY)**

我們需要一個量度 $H(p_1; p_2; \dots; p_n)$ 來衡量從具有概率 $p_i$ 的可能事件中選擇時涉及的「選擇」量或對結果的「不確定性」。

- **熵的數學形式 (Mathematical form of Entropy):** 唯一滿足連續性、與可能性數量單調遞增性，以及選擇分解（加權和）這三個合理假設的函數形式是 $H = -K \sum_{i=1}^n p_i \log p_i$。
- 這個形式 $H$ 在資訊理論中扮演核心角色，並被稱為**熵 (entropy)**。
- **條件熵 (Conditional Entropy $H_x(y)$):** 當我們已知 $x$ 時，對 $y$ 的平均不確定性。其關係為 $H(x, y) = H(x) + H_x(y)$。知識永遠不會增加不確定性，因此 $H(y) \ge H_x(y)$。

#### **7. 資訊源的熵 (THE ENTROPY OF AN INFORMATION SOURCE)**

- **源熵的定義 (Source Entropy Definition):** 資訊源的熵 $H$ 定義為每符號文字的熵，即所有可能狀態的熵 $H_i$ 的平均值，按該狀態發生的概率 $P_i$ 加權。 $$H = \sum_i P_i H_i = -\sum_{i, j} P_i p_i(j) \log p_i(j)$$
- **典型長序列的概率 (Probability of Long Sequences):** 對於任何來源，當序列長度 $N$ 很大時，絕大多數序列的概率 $p$ 都滿足 $\frac{\log(1/p)}{N}$ 非常接近 $H$。
- **冗餘度 (Redundancy):** 資訊源的熵與其在相同符號限制下能達到的最大熵的比值稱為**相對熵 (relative entropy)**。冗餘度則定義為 1 減去相對熵。例如，普通英文的冗餘度約為 $50%$。

#### **9. 無雜訊頻道的基礎定理 (THE FUNDAMENTAL THEOREM FOR A NOISELESS CHANNEL)**

- **定理 9 (Theorem 9):** 若源的熵為 $H$（位元/符號），頻道容量為 $C$（位元/秒），則可以對源輸出進行編碼，使其以平均速率 $C/H$ 符號每秒傳輸，其中誤差 $\epsilon$ 可任意小。不可能以大於 $C/H$ 的速率傳輸。
- **編碼操作 (Encoding Operation):** 一種實現接近理想編碼的方法是將長度 $N$ 的訊息按概率降序排列，並將累積概率 $P_s$ 擴展為二進制數字，其中高概率訊息由較短的代碼表示。

### **離散有雜訊頻道 (PART II: THE DISCRETE CHANNEL WITH NOISE)**

#### **11. 有雜訊離散頻道的表示 (REPRESENTATION OF A NOISY DISCRETE CHANNEL)**

有雜訊頻道是指接收到的訊號 $E$ 不總是與發出的訊號 $S$ 相同，而是 $E = f(S, N)$，其中 $N$ 是雜訊，一個隨機變數。

- **轉移概率 (Transition Probabilities):** 在最一般的有雜訊離散頻道中，需要一組概率 $p_{\nu, i}(\mu, j)$ 來描述：在頻道狀態 $\nu$ 傳輸符號 $i$ 時，接收到符號 $j$ 並轉換到狀態 $\mu$ 的概率。

#### **12. 模糊度與頻道容量 (EQUIVOCATION AND CHANNEL CAPACITY)**

- **模糊度 (Equivocation $H_y(x)$):** 由於雜訊，我們無法確定地重建原始訊息。模糊度定義為訊息的條件熵 $H_y(x)$，即在已知接收訊號時，對原始訊息的不確定性。
- **傳輸速率 $R$ (Rate of Transmission):** 實際傳輸速率是資訊源的產生速率減去模糊度： $$R = H(x) - H_y(x)$$
- **頻道容量 $C$ (Channel Capacity):** 定義為最大可能的傳輸速率，即在所有可能的輸入資訊源中 $R$ 的最大值。 $$C = \text{Max} [H(x) - H_y(x)]$$

#### **13. 有雜訊離散頻道的基礎定理 (THE FUNDAMENTAL THEOREM FOR A DISCRETE CHANNEL WITH NOISE)**

- **定理 11 (Theorem 11):** 如果頻道容量為 $C$，源熵為 $H$。若 $H \le C$，則存在一種編碼系統，可以使傳輸的錯誤頻率或模糊度任意小。若 $H > C$，則模糊度 $H_y(x)$ 必然大於或等於 $H - C$。
- **意義 (Significance):** 這一定理證明了 $C$ 具有明確的意義：我們可以以 $C$ 的速率傳輸資訊，並將錯誤的可能性縮小到任意小。嘗試以更高速率傳輸則必然會產生不確定性。

### **數學預備 (PART III: MATHEMATICAL PRELIMINARIES)**

#### **20. 連續分佈的熵 (ENTROPY OF A CONTINUOUS DISTRIBUTION)**

連續分佈的熵 $H$ 定義為： $$H = -\int p(x) \log p(x) dx$$

- **高斯分佈 (Gaussian Distribution):** 在標準差固定的條件下，給出最大熵的一維分佈是高斯分佈。
- **坐標系依賴性 (Coordinate System Dependence):** 連續熵的衡量是**相對於坐標系**的。然而，資訊率和頻道容量是兩個熵之間的**差異**，因此與坐標系無關。

#### **21. 函數系的熵 (ENTROPY OF AN ENSEMBLE OF FUNCTIONS)**

- **白雜訊 (White Noise):** 在給定平均功率 $N$ 和頻帶 $W$ 限制下，白雜訊具有最大的可能熵。
- **熵功率 (Entropy Power $N_1$):** 定義為與原始函數系具有相同熵的白雜訊的功率。任何雜訊的熵功率 $N_1$ 總是小於或等於其實際平均功率 $N$。

### **連續頻道 (PART IV: THE CONTINUOUS CHANNEL)**

#### **24. 連續頻道的容量 (THE CAPACITY OF A CONTINUOUS CHANNEL)**

連續頻道的傳輸速率 $R$ 仍定義為 $R = H(x) - H_y(x)$，容量 $C$ 是 $R$ 的最大值。

- **獨立相加雜訊 (Independent Additive Noise):** 若訊號 $x$ 和雜訊 $n$ 獨立，且接收訊號 $y = x + n$，則速率可以表示為接收訊號的熵減去雜訊的熵： $$R = H(y) - H(n)$$

#### **25. 平均功率限制下的頻道容量 (CHANNEL CAPACITY WITH AN AVERAGE POWER LIMITATION)**

- **定理 17 (Theorem 17):** 頻道容量 $C$ 在頻寬 $W$、白熱雜訊功率 $N$ 以及發射器平均功率限制 $P$ 的條件下，由以下公式給出： $$C = W \log \frac{P+N}{N}$$ 為了近似達到這個極限速率，發射訊號在統計特性上必須近似於白雜訊。
- **任意雜訊的容量界限 (Bounds for Arbitrary Noise):** 對於任意雜訊，容量 $C$ 的界限為： $$W \log \frac{P+N_1}{N_1} \le C \le W \log \frac{P+N}{N_1}$$ 其中 $N_1$ 是雜訊的熵功率， $N$ 是雜訊的平均功率。

### **連續源的速率 (PART V: THE RATE FOR A CONTINUOUS SOURCE)**

#### **27. 傳真度評估函數 (FIDELITY EVALUATION FUNCTIONS)**

對於連續源，通常只需要達到一定的傳真度 (fidelity)。傳真度的評估 $v$ 在訊息持續時間 $T$ 夠長的情況下，可以表示為輸入訊息 $x$ 和恢復訊息 $y$ 之間的**距離函數 (distance function) $\eta(x, y)$** 的平均值： $$v = \iint P(x, y) \eta(x, y) dx dy$$ 一個常用的例子是**均方根 (R.M.S.) 準則**，其中 $\eta(x, y)$ 是 $x(t)$ 和 $y(t)$ 之間平均平方誤差的度量。

#### **28. 源相對於傳真度評估的速率 (THE RATE FOR A SOURCE RELATIVE TO A FIDELITY EVALUATION)**

- **源速率 $R_1$ 的定義 (Definition of Source Rate $R_1$):** 給定要求的傳真度 $v_1$，源產生資訊的速率 $R_1$ 定義為當傳真度固定在 $v_1$ 時，傳輸速率 $R$ 的**最小值**。
- **定理 21 (Theorem 21):** 如果一個源的速率為 $R_1$，它就能夠在容量 $C \ge R_1$ 的頻道上傳輸，並滿足要求的傳真度。

#### **29. 速率的計算 (THE CALCULATION OF RATES)**

- **定理 22 (Theorem 22):** 對於功率為 $Q$、頻寬為 $W_1$ 的白雜訊源，相對於 R.M.S. 傳真度的速率 $R$ 為： $$R = W_1 \log \frac{Q}{N}$$ 其中 $N$ 是允許的原始訊息和恢復訊息之間的平均均方誤差。

---

**總結**

本論文提供了一個全面且嚴謹的通訊數學理論，從基本概念（如資訊的對數測度、熵）出發，將通訊問題分解為對資訊源的統計特性分析 $H$ 和對傳輸介質的容量分析 $C$。對於無雜訊和有雜訊的離散及連續頻道，它確立了兩大基礎定理：在無雜訊情況下，最大傳輸率與 $C/H$ 成正比；在有雜訊情況下，存在一個明確的容量 $C$，只要傳輸速率不超過 $C$，錯誤率即可任意降低。這些原理，特別是 $C=W \log(1+P/N)$ 的香農極限公式，構成了現代通訊系統設計和理論的基石。